{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7145/437852176.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from scipy.stats import uniform\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, precision_recall_curve,f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  \"./spoty_train_multiclass.csv\"\n",
    "train = pd.read_csv(train_data)\n",
    "test_data = \"./spoty_test_multiclass.csv\"\n",
    "test = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data():\n",
    "    y_train = train['genre']\n",
    "    X_train = train.drop('genre',axis='columns')\n",
    "    y_test = test['genre']\n",
    "    X_test = test.drop('genre',axis='columns')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6000 candidates, totalling 30000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "mms = StandardScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "if gridSearch:\n",
    "    c_dist = uniform(0.01, 2) # continuous value\n",
    "    elastic_l1_ratio = uniform(0, 1)\n",
    "    # not all combinations are valid, thats why I use a list of dicts\n",
    "    parameters = [{\"C\": c_dist, \"solver\":[\"newton-cg\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"lbfgs\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"liblinear\"], \"penalty\": [\"l1\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"liblinear\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"sag\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"saga\"], \"penalty\": [\"l1\", \"l2\"], \"dual\": [False]},\n",
    "        {\"solver\":[\"saga\"], \"penalty\": [\"none\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"saga\"], \"penalty\": [\"elasticnet\"], \"dual\": [False], \"l1_ratio\": elastic_l1_ratio}]\n",
    "else :\n",
    "    parameters = {'C': [0.6065646519120615], 'dual': [False], 'l1_ratio': [0.5699649107012649], 'penalty': ['elasticnet'], 'solver': ['saga']}\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced',multi_class='multinomial')\n",
    "grid = RandomizedSearchCV(model, parameters, n_iter=6000, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nLogisitc Regression:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'solver': 'saga', 'penalty': 'elasticnet', 'l...</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'solver': 'saga', 'penalty': 'elasticnet', 'l...         0.555907   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.571     0.337     0.424      1168\n",
      "            Emo      0.381     0.528     0.442       472\n",
      "         Hiphop      0.452     0.388     0.418       793\n",
      "            Pop      0.131     0.438     0.202       146\n",
      "            Rap      0.354     0.469     0.404       537\n",
      "            RnB      0.402     0.314     0.353       576\n",
      "     Trap Metal      0.382     0.561     0.454       542\n",
      "Underground Rap      0.501     0.322     0.392      1188\n",
      "            dnb      0.765     0.798     0.781       722\n",
      "      hardstyle      0.576     0.588     0.582       701\n",
      "      psytrance      0.786     0.861     0.822       796\n",
      "      techhouse      0.717     0.775     0.745       681\n",
      "         techno      0.793     0.808     0.801       825\n",
      "         trance      0.656     0.647     0.652       862\n",
      "           trap      0.665     0.672     0.669       705\n",
      "\n",
      "       accuracy                          0.563     10714\n",
      "      macro avg      0.542     0.567     0.543     10714\n",
      "   weighted avg      0.579     0.563     0.562     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[394  52  28  44  51  29 161 119  50  48   4  25  26 109  28]\n",
      " [  5 249   7  42   9  35   4   2  27  49   0   1   0  27  15]\n",
      " [ 45  46 308  61  72  86  46  71  26   5   0  14   0   2  11]\n",
      " [  5  19  11  64   7  18   1   5   4   1   0   7   0   2   2]\n",
      " [ 18   6  32  44 252  34  32  81   1   2   0  17   3   9   6]\n",
      " [ 16  68  86  94  66 181  12  32   7   0   0   8   0   2   4]\n",
      " [ 37  16   8  18  38   3 304  58  12   9   0   6   0   3  30]\n",
      " [ 68  24 178  83 183  46 178 383  14   4   0  10   0   3  14]\n",
      " [ 14  28   9   5   0   4   1   0 576  46  16   0   0   0  23]\n",
      " [ 24  95   1   6   0   3  21   0  19 412  23   1   0  27  69]\n",
      " [  5   0   0   0   0   1   1   0   4   3 685  13  35  44   5]\n",
      " [  7   5   3   9  11   3   3   5   0   3   2 528  81  15   6]\n",
      " [  6   0   0   1   2   0   0   0   0   0  38  73 667  36   2]\n",
      " [ 23  17   1   6   6   2  10   0   0  56 103  27  29 558  24]\n",
      " [ 23  29   9  12  14   5  22   8  13  77   0   6   0  13 474]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest:\n",
      "- Best Params: {'n_estimators': 889, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 1400, 'bootstrap': False}\n",
      "- Accuracy: { train: 1.000, CV: 0.996, test: 0.995}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "\n",
    "if gridSearch:\n",
    "    n_est = [int(x) for x in np.linspace(start = 1, stop = 1000, num = 10)]\n",
    "    max_d = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_d.append(None)\n",
    "    parameters = {'n_estimators': n_est, 'max_features': ['log2','sqrt',None], 'bootstrap': [True,False], 'max_depth': max_d, 'min_samples_split': [5, 6, 8, 10], 'min_samples_leaf': [1, 2, 4]}\n",
    "else :\n",
    "    parameters = {'n_estimators': [889], 'min_samples_split': [10], 'min_samples_leaf': [1], 'max_features': ['auto'], 'max_depth': [1400], 'bootstrap': [False]}\n",
    "    \n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "grid = RandomizedSearchCV(model, parameters, n_iter=1000, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nRandom Forest:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_estimators': 889, 'min_samples_split': 10,...</td>\n",
       "      <td>0.995559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'n_estimators': 889, 'min_samples_split': 10,...         0.995559   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.999     0.999     0.999      1168\n",
      "            Emo      0.996     0.979     0.987       472\n",
      "         Hiphop      0.990     0.991     0.991       793\n",
      "            Pop      1.000     0.959     0.979       146\n",
      "            Rap      0.989     0.991     0.990       537\n",
      "            RnB      0.998     0.993     0.996       576\n",
      "     Trap Metal      0.978     0.998     0.988       542\n",
      "Underground Rap      0.999     0.999     0.999      1188\n",
      "            dnb      1.000     1.000     1.000       722\n",
      "      hardstyle      1.000     1.000     1.000       701\n",
      "      psytrance      1.000     0.994     0.997       796\n",
      "      techhouse      0.988     0.993     0.990       681\n",
      "         techno      0.996     0.999     0.998       825\n",
      "         trance      0.992     0.998     0.995       862\n",
      "           trap      0.999     0.997     0.998       705\n",
      "\n",
      "       accuracy                          0.995     10714\n",
      "      macro avg      0.995     0.993     0.994     10714\n",
      "   weighted avg      0.995     0.995     0.995     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[1167    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0  462    0    0    5    0    4    0    0    0    0    1    0    0\n",
      "     0]\n",
      " [   0    0  786    0    0    0    2    0    0    0    0    4    0    1\n",
      "     0]\n",
      " [   0    0    3  140    0    0    1    0    0    0    0    2    0    0\n",
      "     0]\n",
      " [   0    1    0    0  532    1    3    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    1  572    2    0    0    0    0    1    0    0\n",
      "     0]\n",
      " [   0    1    0    0    0    0  541    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0    0    0    0    0    0 1187    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0  722    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  701    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  791    0    0    4\n",
      "     1]\n",
      " [   0    0    2    0    0    0    0    0    0    0    0  676    2    1\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0  824    1\n",
      "     0]\n",
      " [   0    0    1    0    0    0    0    0    0    0    0    0    1  860\n",
      "     0]\n",
      " [   0    0    2    0    0    0    0    0    0    0    0    0    0    0\n",
      "   703]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear SVM:\n",
      "- Best Params: {'penalty': 'l2', 'loss': 'squared_hinge', 'dual': False, 'C': 1.7045034775682508}\n",
      "- Accuracy: { train: 0.540, CV: 0.538, test: 0.544}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "mms = StandardScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "if gridSearch:\n",
    "    c_dist = uniform(0.01, 2) \n",
    "    # not all combinations are valid, thats why I use a list of dicts (l1 with hinge)\n",
    "    parameters = [{'C': c_dist,  'penalty': ['l1'], 'loss': ['squared_hinge'], 'dual': [False]},\n",
    "        {'C': c_dist,  'penalty': ['l2'], 'loss': ['hinge','squared_hinge'], 'dual': [False]}]\n",
    "else:\n",
    "    parameters = {'C': [1.7045034775682508], 'dual': [False], 'loss': ['squared_hinge'], 'penalty': ['l2']} \n",
    "\n",
    "model = svm.LinearSVC(tol = 0.00005, class_weight='balanced')\n",
    "grid = RandomizedSearchCV(model, parameters, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nLinear SVM:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'squared_hinge', 'du...</td>\n",
       "      <td>0.537825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'penalty': 'l2', 'loss': 'squared_hinge', 'du...         0.537825   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.568     0.320     0.409      1168\n",
      "            Emo      0.332     0.536     0.410       472\n",
      "         Hiphop      0.452     0.393     0.421       793\n",
      "            Pop      0.092     0.110     0.100       146\n",
      "            Rap      0.322     0.462     0.380       537\n",
      "            RnB      0.372     0.316     0.342       576\n",
      "     Trap Metal      0.379     0.432     0.404       542\n",
      "Underground Rap      0.515     0.323     0.397      1188\n",
      "            dnb      0.669     0.831     0.741       722\n",
      "      hardstyle      0.602     0.496     0.544       701\n",
      "      psytrance      0.740     0.834     0.784       796\n",
      "      techhouse      0.623     0.771     0.689       681\n",
      "         techno      0.735     0.807     0.769       825\n",
      "         trance      0.623     0.636     0.630       862\n",
      "           trap      0.594     0.679     0.634       705\n",
      "\n",
      "       accuracy                          0.544     10714\n",
      "      macro avg      0.508     0.530     0.510     10714\n",
      "   weighted avg      0.549     0.544     0.536     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[374  61  30  18  72  29 135 110  73  37   3  37  44 117  28]\n",
      " [  7 253   6   5  11  38   5   3  46  32   1  10   0  39  16]\n",
      " [ 44  61 312  14  84  94  34  64  29   5   1  23   4   9  15]\n",
      " [  3  35  10  16  10  22   1   5  15   2   0  21   1   2   3]\n",
      " [ 12   9  31  19 248  37  28  83   1   1   1  35   2  17  13]\n",
      " [ 20  83  89  34  78 182   8  31  21   3   0  20   0   1   6]\n",
      " [ 36  17   9   9  39   4 234  55  29   8   0  17   3   9  73]\n",
      " [ 77  36 177  46 184  61 143 384  23   7   0  22   2   3  23]\n",
      " [  8  30  12   1   0   6   1   0 600  25   9   1   0   0  29]\n",
      " [ 23 117   4   3   0   4  16   1  26 348  24   4   0  51  80]\n",
      " [ 10   0   2   0   0   1   1   0   4   1 664  14  70  23   6]\n",
      " [  5   7   1   3  18   1   1   3   0   4   6 525  83  14  10]\n",
      " [  3   0   0   0   2   0   0   0   0   1  49  73 666  28   3]\n",
      " [ 13  20   0   1  11   7   2   0   1  39 139  28  30 548  23]\n",
      " [ 24  34   7   5  12   3   8   7  29  65   0  13   1  18 479]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "\n",
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "\n",
      "SVM with RBF kernel:\n",
      "- Best Params: {'C': 1.969173457625457, 'gamma': 'auto'}\n",
      "- Accuracy: { train: 0.698, CV: 0.639, test: 0.640}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "mms = StandardScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "if gridSearch:\n",
    "    c_dist = uniform(0.01, 2)\n",
    "    param = {\"C\": c_dist, \"gamma\": [\"scale\", \"auto\"]}\n",
    "else :\n",
    "    param = {'C': [1.969173457625457], 'gamma': ['auto']}\n",
    "\n",
    "model = svm.SVC(kernel=\"rbf\",class_weight='balanced')\n",
    "grid = RandomizedSearchCV(model, param, n_iter=1000, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nSVM with RBF kernel:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>{'C': 1.9709713269380136, 'gamma': 'auto'}</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>{'C': 1.9649902794888936, 'gamma': 'auto'}</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>{'C': 1.969173457625457, 'gamma': 'auto'}</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'C': 1.9635221763806743, 'gamma': 'auto'}</td>\n",
       "      <td>0.638474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>{'C': 1.9708195947420704, 'gamma': 'auto'}</td>\n",
       "      <td>0.638474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         params  mean_test_score  \\\n",
       "608  {'C': 1.9709713269380136, 'gamma': 'auto'}         0.638514   \n",
       "180  {'C': 1.9649902794888936, 'gamma': 'auto'}         0.638514   \n",
       "51    {'C': 1.969173457625457, 'gamma': 'auto'}         0.638514   \n",
       "48   {'C': 1.9635221763806743, 'gamma': 'auto'}         0.638474   \n",
       "831  {'C': 1.9708195947420704, 'gamma': 'auto'}         0.638474   \n",
       "\n",
       "     rank_test_score  \n",
       "608                1  \n",
       "180                1  \n",
       "51                 1  \n",
       "48                 4  \n",
       "831                4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.626     0.426     0.507      1240\n",
      "            Emo      0.571     0.657     0.611       475\n",
      "         Hiphop      0.487     0.472     0.479       778\n",
      "            Pop      0.144     0.442     0.218       129\n",
      "            Rap      0.374     0.542     0.443       552\n",
      "            RnB      0.387     0.372     0.380       578\n",
      "     Trap Metal      0.428     0.511     0.465       619\n",
      "Underground Rap      0.472     0.346     0.399      1137\n",
      "            dnb      0.923     0.930     0.927       759\n",
      "      hardstyle      0.780     0.810     0.794       730\n",
      "      psytrance      0.898     0.893     0.895       746\n",
      "      techhouse      0.822     0.837     0.829       706\n",
      "         techno      0.840     0.848     0.844       764\n",
      "         trance      0.773     0.802     0.787       859\n",
      "           trap      0.782     0.740     0.760       692\n",
      "\n",
      "       accuracy                          0.640     10764\n",
      "      macro avg      0.621     0.642     0.623     10764\n",
      "   weighted avg      0.654     0.640     0.642     10764\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[528  30  22  32  67  57 150 151  29  28   4  22   8  81  31]\n",
      " [ 15 312   5  47   3  30   8   5   8  30   0   1   0   8   3]\n",
      " [ 43  21 367  27  79 113  32  68   7   2   0   9   0   3   7]\n",
      " [  3  22   6  57   6  21   1   9   0   3   0   0   0   1   0]\n",
      " [ 17   5  33  25 299  40  36  87   1   2   0   2   1   1   3]\n",
      " [ 16  40 102  97  55 215   9  29   2   2   0   8   0   1   2]\n",
      " [ 59  16  17  13  58   8 316  85   9   7   0   4   0   6  21]\n",
      " [ 74  12 182  49 212  52 139 393   3   4   0  10   1   1   5]\n",
      " [  3  24   8   4   0   5   6   1 706   0   1   0   0   0   1]\n",
      " [ 12  29   3   5   1   2  12   0   0 591  12   0   0   0  63]\n",
      " [  6   0   1   1   0   1   2   0   0   3 666   0  22  40   4]\n",
      " [  4   1   1  19   7   3   9   0   0   0   0 591  54  17   0]\n",
      " [  8   0   1   0   0   1   0   0   0   0  14  61 648  31   0]\n",
      " [ 40  20   0   9   2   2   4   0   0   0  42  11  37 689   3]\n",
      " [ 16  14   5  10  10   5  15   4   0  86   3   0   0  12 512]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
