{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12586/437852176.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from scipy.stats import uniform\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, precision_recall_curve,f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  \"./spoty_train_multiclass.csv\"\n",
    "train = pd.read_csv(train_data)\n",
    "test_data = \"./spoty_test_multiclass.csv\"\n",
    "test = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data():\n",
    "    y_train = train['genre']\n",
    "    X_train = train.drop('genre',axis='columns')\n",
    "    y_test = test['genre']\n",
    "    X_test = test.drop('genre',axis='columns')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/miriam/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logisitc Regression:\n",
      "- Best Params: {'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.5699649107012649, 'dual': False, 'C': 0.6065646519120615}\n",
      "- Accuracy: { train: 0.559, CV: 0.556, test: 0.563}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "mms = StandardScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "if gridSearch:\n",
    "    c_dist = uniform(0.01, 2) # continuous value\n",
    "    elastic_l1_ratio = uniform(0, 1)\n",
    "    # not all combinations are valid, thats why I use a list of dicts\n",
    "    parameters = [{\"C\": c_dist, \"solver\":[\"newton-cg\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"lbfgs\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"liblinear\"], \"penalty\": [\"l1\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"liblinear\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"sag\"], \"penalty\": [\"l2\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"saga\"], \"penalty\": [\"l1\", \"l2\"], \"dual\": [False]},\n",
    "        {\"solver\":[\"saga\"], \"penalty\": [\"none\"], \"dual\": [False]},\n",
    "        {\"C\": c_dist, \"solver\":[\"saga\"], \"penalty\": [\"elasticnet\"], \"dual\": [False], \"l1_ratio\": elastic_l1_ratio}]\n",
    "else :\n",
    "    parameters = {'C': [0.6065646519120615], 'dual': [False], 'l1_ratio': [0.5699649107012649], 'penalty': ['elasticnet'], 'solver': ['saga']}\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced',multi_class='multinomial')\n",
    "grid = RandomizedSearchCV(model, parameters, n_iter=6000, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nLogisitc Regression:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'solver': 'saga', 'penalty': 'elasticnet', 'l...</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'solver': 'saga', 'penalty': 'elasticnet', 'l...         0.555907   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.571     0.337     0.424      1168\n",
      "            Emo      0.381     0.528     0.442       472\n",
      "         Hiphop      0.452     0.388     0.418       793\n",
      "            Pop      0.131     0.438     0.202       146\n",
      "            Rap      0.354     0.469     0.404       537\n",
      "            RnB      0.402     0.314     0.353       576\n",
      "     Trap Metal      0.382     0.561     0.454       542\n",
      "Underground Rap      0.501     0.322     0.392      1188\n",
      "            dnb      0.765     0.798     0.781       722\n",
      "      hardstyle      0.576     0.588     0.582       701\n",
      "      psytrance      0.786     0.861     0.822       796\n",
      "      techhouse      0.717     0.775     0.745       681\n",
      "         techno      0.793     0.808     0.801       825\n",
      "         trance      0.656     0.647     0.652       862\n",
      "           trap      0.665     0.672     0.669       705\n",
      "\n",
      "       accuracy                          0.563     10714\n",
      "      macro avg      0.542     0.567     0.543     10714\n",
      "   weighted avg      0.579     0.563     0.562     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[394  52  28  44  51  29 161 119  50  48   4  25  26 109  28]\n",
      " [  5 249   7  42   9  35   4   2  27  49   0   1   0  27  15]\n",
      " [ 45  46 308  61  72  86  46  71  26   5   0  14   0   2  11]\n",
      " [  5  19  11  64   7  18   1   5   4   1   0   7   0   2   2]\n",
      " [ 18   6  32  44 252  34  32  81   1   2   0  17   3   9   6]\n",
      " [ 16  68  86  94  66 181  12  32   7   0   0   8   0   2   4]\n",
      " [ 37  16   8  18  38   3 304  58  12   9   0   6   0   3  30]\n",
      " [ 68  24 178  83 183  46 178 383  14   4   0  10   0   3  14]\n",
      " [ 14  28   9   5   0   4   1   0 576  46  16   0   0   0  23]\n",
      " [ 24  95   1   6   0   3  21   0  19 412  23   1   0  27  69]\n",
      " [  5   0   0   0   0   1   1   0   4   3 685  13  35  44   5]\n",
      " [  7   5   3   9  11   3   3   5   0   3   2 528  81  15   6]\n",
      " [  6   0   0   1   2   0   0   0   0   0  38  73 667  36   2]\n",
      " [ 23  17   1   6   6   2  10   0   0  56 103  27  29 558  24]\n",
      " [ 23  29   9  12  14   5  22   8  13  77   0   6   0  13 474]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Random Forest:\n",
      "- Best Params: {'n_estimators': 645, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 200, 'bootstrap': True}\n",
      "- Accuracy: { train: 0.979, CV: 0.680, test: 0.695}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "\n",
    "if gridSearch:\n",
    "    n_est = [int(x) for x in np.linspace(start = 1, stop = 1000, num = 10)]\n",
    "    max_d = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_d.append(None)\n",
    "    parameters = {'n_estimators': n_est, 'max_features': ['log2','sqrt',None], 'bootstrap': [True,False], 'max_depth': max_d, 'min_samples_split': [5, 6, 8, 10], 'min_samples_leaf': [1, 2, 4]}\n",
    "else :\n",
    "    parameters = {'n_estimators': [645], 'min_samples_split': [5], 'min_samples_leaf': [2], 'max_features': ['sqrt'], 'max_depth': [200], 'bootstrap': [True]}\n",
    "    \n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "grid = RandomizedSearchCV(model, parameters, n_iter=1000, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nRandom Forest:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'n_estimators': 667, 'min_samples_split': 6, ...</td>\n",
       "      <td>0.681602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'n_estimators': 667, 'min_samples_split': 6, ...         0.681602   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.610     0.544     0.575      1168\n",
      "            Emo      0.679     0.750     0.713       472\n",
      "         Hiphop      0.481     0.469     0.475       793\n",
      "            Pop      0.279     0.116     0.164       146\n",
      "            Rap      0.584     0.473     0.523       537\n",
      "            RnB      0.438     0.479     0.458       576\n",
      "     Trap Metal      0.485     0.491     0.488       542\n",
      "Underground Rap      0.467     0.508     0.487      1188\n",
      "            dnb      0.951     0.992     0.971       722\n",
      "      hardstyle      0.839     0.886     0.862       701\n",
      "      psytrance      0.892     0.935     0.913       796\n",
      "      techhouse      0.862     0.880     0.871       681\n",
      "         techno      0.851     0.864     0.857       825\n",
      "         trance      0.820     0.838     0.829       862\n",
      "           trap      0.818     0.777     0.797       705\n",
      "\n",
      "       accuracy                          0.695     10714\n",
      "      macro avg      0.670     0.667     0.665     10714\n",
      "   weighted avg      0.690     0.695     0.691     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[635  19  19   1  19  34  94 189  17  25   6  20   9  58  23]\n",
      " [ 13 354   5   9   5  26   6  13   3  16   0   3   1  12   6]\n",
      " [ 63  20 372   8  36 116  31 125   8   2   0   1   1   4   6]\n",
      " [  8  27  11  17   5  51   3  13   1   0   0   7   0   2   1]\n",
      " [ 18   8  45   2 254  38  14 155   1   0   0   1   0   1   0]\n",
      " [ 31  38 108  17  22 276   6  69   0   4   0   2   1   1   1]\n",
      " [ 83  11  17   1   9  10 266 113   2   3   0   2   0   4  21]\n",
      " [106   9 187   4  79  70 108 604   5   2   0   5   0   1   8]\n",
      " [  0   3   3   0   0   0   0   0 716   0   0   0   0   0   0]\n",
      " [ 10  10   0   0   1   2   5   0   0 621   7   0   0   0  45]\n",
      " [  3   0   0   0   0   0   0   0   0   0 744   1  16  27   5]\n",
      " [  6   6   0   0   2   2   3   4   0   0   0 599  54   5   0]\n",
      " [  8   0   0   0   0   0   0   0   0   0  30  45 713  29   0]\n",
      " [ 24   7   1   2   0   3   4   1   0   0  41   9  42 722   6]\n",
      " [ 33   9   6   0   3   2   9   7   0  67   6   0   1  14 548]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Linear SVM:\n",
      "- Best Params: {'penalty': 'l2', 'loss': 'squared_hinge', 'dual': False, 'C': 1.7045034775682508}\n",
      "- Accuracy: { train: 0.540, CV: 0.538, test: 0.544}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "mms = StandardScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "if gridSearch:\n",
    "    c_dist = uniform(0.01, 2) \n",
    "    # not all combinations are valid, thats why I use a list of dicts (l1 with hinge)\n",
    "    parameters = [{'C': c_dist,  'penalty': ['l1'], 'loss': ['squared_hinge'], 'dual': [False]},\n",
    "        {'C': c_dist,  'penalty': ['l2'], 'loss': ['hinge','squared_hinge'], 'dual': [False]}]\n",
    "else:\n",
    "    parameters = {'C': [1.7045034775682508], 'dual': [False], 'loss': ['squared_hinge'], 'penalty': ['l2']} \n",
    "\n",
    "model = svm. = 0.00005, class_weight='balanced')\n",
    "grid = RandomizedSearchCV(model, parameters, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nLinear SVM:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'penalty': 'l2', 'loss': 'squared_hinge', 'du...</td>\n",
       "      <td>0.537825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score  \\\n",
       "0  {'penalty': 'l2', 'loss': 'squared_hinge', 'du...         0.537825   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.568     0.320     0.409      1168\n",
      "            Emo      0.332     0.536     0.410       472\n",
      "         Hiphop      0.452     0.393     0.421       793\n",
      "            Pop      0.092     0.110     0.100       146\n",
      "            Rap      0.322     0.462     0.380       537\n",
      "            RnB      0.372     0.316     0.342       576\n",
      "     Trap Metal      0.379     0.432     0.404       542\n",
      "Underground Rap      0.515     0.323     0.397      1188\n",
      "            dnb      0.669     0.831     0.741       722\n",
      "      hardstyle      0.602     0.496     0.544       701\n",
      "      psytrance      0.740     0.834     0.784       796\n",
      "      techhouse      0.623     0.771     0.689       681\n",
      "         techno      0.735     0.807     0.769       825\n",
      "         trance      0.623     0.636     0.630       862\n",
      "           trap      0.594     0.679     0.634       705\n",
      "\n",
      "       accuracy                          0.544     10714\n",
      "      macro avg      0.508     0.530     0.510     10714\n",
      "   weighted avg      0.549     0.544     0.536     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[374  61  30  18  72  29 135 110  73  37   3  37  44 117  28]\n",
      " [  7 253   6   5  11  38   5   3  46  32   1  10   0  39  16]\n",
      " [ 44  61 312  14  84  94  34  64  29   5   1  23   4   9  15]\n",
      " [  3  35  10  16  10  22   1   5  15   2   0  21   1   2   3]\n",
      " [ 12   9  31  19 248  37  28  83   1   1   1  35   2  17  13]\n",
      " [ 20  83  89  34  78 182   8  31  21   3   0  20   0   1   6]\n",
      " [ 36  17   9   9  39   4 234  55  29   8   0  17   3   9  73]\n",
      " [ 77  36 177  46 184  61 143 384  23   7   0  22   2   3  23]\n",
      " [  8  30  12   1   0   6   1   0 600  25   9   1   0   0  29]\n",
      " [ 23 117   4   3   0   4  16   1  26 348  24   4   0  51  80]\n",
      " [ 10   0   2   0   0   1   1   0   4   1 664  14  70  23   6]\n",
      " [  5   7   1   3  18   1   1   3   0   4   6 525  83  14  10]\n",
      " [  3   0   0   0   2   0   0   0   0   1  49  73 666  28   3]\n",
      " [ 13  20   0   1  11   7   2   0   1  39 139  28  30 548  23]\n",
      " [ 24  34   7   5  12   3   8   7  29  65   0  13   1  18 479]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "SVM with RBF kernel:\n",
      "- Best Params: {'gamma': 'auto', 'C': 1.969173457625457}\n",
      "- Accuracy: { train: 0.691, CV: 0.633, test: 0.646}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_data() # loading data\n",
    "mms = StandardScaler().fit(X_train)\n",
    "X_train = mms.transform(X_train)\n",
    "X_test = mms.transform(X_test)\n",
    "\n",
    "if gridSearch:\n",
    "    c_dist = uniform(0.01, 2)\n",
    "    param = {\"C\": c_dist, \"gamma\": [\"scale\", \"auto\"]}\n",
    "else :\n",
    "    param = {'C': [1.969173457625457], 'gamma': ['auto']}\n",
    "\n",
    "model = svm.SVC(kernel=\"rbf\",class_weight='balanced')\n",
    "grid = RandomizedSearchCV(model, param, n_iter=1000, cv=5, random_state=0, n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "test_acc = best_model.score(X=X_test, y=y_test)\n",
    "train_acc = best_model.score(X=X_train, y=y_train)\n",
    "\n",
    "print('\\nSVM with RBF kernel:')\n",
    "print('- Best Params:', grid.best_params_)\n",
    "print(f'- Accuracy: {{ train: {train_acc:.3f}, CV: {grid.best_score_:.3f}, test: {test_acc:.3f}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'gamma': 'auto', 'C': 1.969173457625457}</td>\n",
       "      <td>0.633476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params  mean_test_score  rank_test_score\n",
       "0  {'gamma': 'auto', 'C': 1.969173457625457}         0.633476                1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Dark Trap      0.616     0.431     0.507      1168\n",
      "            Emo      0.573     0.633     0.602       472\n",
      "         Hiphop      0.464     0.426     0.444       793\n",
      "            Pop      0.169     0.438     0.244       146\n",
      "            Rap      0.384     0.566     0.457       537\n",
      "            RnB      0.408     0.384     0.395       576\n",
      "     Trap Metal      0.424     0.565     0.484       542\n",
      "Underground Rap      0.510     0.360     0.422      1188\n",
      "            dnb      0.911     0.932     0.921       722\n",
      "      hardstyle      0.777     0.833     0.804       701\n",
      "      psytrance      0.874     0.915     0.894       796\n",
      "      techhouse      0.807     0.828     0.817       681\n",
      "         techno      0.849     0.847     0.848       825\n",
      "         trance      0.784     0.799     0.791       862\n",
      "           trap      0.796     0.732     0.763       705\n",
      "\n",
      "       accuracy                          0.646     10714\n",
      "      macro avg      0.623     0.646     0.626     10714\n",
      "   weighted avg      0.657     0.646     0.646     10714\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      " [[503  28  33  35  65  29 148 125  25  35   6  31   9  78  18]\n",
      " [ 10 299   5  44   5  33   5   2  13  31   0   3   0  11  11]\n",
      " [ 43  28 338  41  79 112  41  77  14   8   0   3   1   3   5]\n",
      " [  4  18   7  64   8  23   2   6   2   2   0   7   0   3   0]\n",
      " [ 13   5  35  17 304  40  28  85   1   1   0   1   0   1   6]\n",
      " [ 29  43  88  80  54 221  13  29   1   3   0   6   0   2   7]\n",
      " [ 51   9  11  10  35   9 306  77   4   6   0   4   0   5  15]\n",
      " [ 82  11 194  44 212  59 134 428   6   4   0   5   0   1   8]\n",
      " [  6  27   7   1   0   3   3   0 673   1   0   0   0   0   1]\n",
      " [ 14  18   1   5   0   3   9   1   0 584  14   0   0   0  52]\n",
      " [  5   0   0   0   0   0   1   0   0   3 728   2  19  33   5]\n",
      " [  8   5   2  15  10   1   6   3   0   0   0 564  60   7   0]\n",
      " [  7   0   0   0   1   1   0   0   0   0  33  57 699  27   0]\n",
      " [ 20  20   1  12   2   2  12   1   0   1  48  15  35 689   4]\n",
      " [ 21  11   6  11  17   6  14   6   0  73   4   1   0  19 516]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid.predict(X_test), digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, grid.predict(X_test))\n",
    "print ('\\nConfusion matrix: \\n', cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
